<div align="center">

# ğŸ§  Gemini Clone

**An AI Agent built with Clean Architecture, RAG, and Real-time Web Search**

[![Next.js](https://img.shields.io/badge/Next.js-16.1-black?logo=next.js)](https://nextjs.org)
[![TypeScript](https://img.shields.io/badge/TypeScript-Strict-blue?logo=typescript)](https://www.typescriptlang.org)
[![Genkit](https://img.shields.io/badge/Google-Genkit-4285F4?logo=google)](https://firebase.google.com/docs/genkit)
[![Tests](https://img.shields.io/badge/Tests-58%20passing-success)](./src)

</div>

---

## ğŸ¯ Overview

A conversational AI agent that demonstrates **Clean Architecture** principles with real-world AI capabilities:

- ğŸ” **Web Search** - Real-time information via Tavily API
- ğŸ“š **RAG (Retrieval-Augmented Generation)** - Semantic search over local documents using OpenAI embeddings
- ğŸ¤– **Multi-Model Support** - Gemini 2.5 Flash & GPT-4o
- ğŸ› ï¸ **Function Calling** - Intelligent tool selection by the LLM

---

## ğŸ—ï¸ Architecture

This project follows **Clean Architecture** with **Domain-Driven Design (DDD)** principles:

```
src/
â”œâ”€â”€ core/                          # ğŸ¯ DOMAIN LAYER (Pure TypeScript)
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ entities/              # Conversation, Message
â”‚   â”‚   â”œâ”€â”€ value-objects/         # MessageRole, MessageContent
â”‚   â”‚   â”œâ”€â”€ interfaces/            # Repository contracts
â”‚   â”‚   â””â”€â”€ ports/                 # Tool interfaces (WebSearch, KnowledgeBase)
â”‚   â””â”€â”€ application/
â”‚       â”œâ”€â”€ use-cases/             # SendMessageUseCase
â”‚       â””â”€â”€ dto/                   # Request/Response DTOs
â”‚
â”œâ”€â”€ infrastructure/                # ğŸ”Œ ADAPTERS LAYER
â”‚   â”œâ”€â”€ ai/
â”‚   â”‚   â”œâ”€â”€ GenkitAgent.ts         # LLM orchestrator
â”‚   â”‚   â”œâ”€â”€ genkit/                # Modular AI components
â”‚   â”‚   â”‚   â”œâ”€â”€ GenkitClient.ts    # AI client initialization
â”‚   â”‚   â”‚   â”œâ”€â”€ ToolRegistry.ts    # Tool definitions
â”‚   â”‚   â”‚   â””â”€â”€ MessageConverter.ts
â”‚   â”‚   â””â”€â”€ prompts/
â”‚   â”‚       â”œâ”€â”€ PromptLoader.ts    # Prompt utilities
â”‚   â”‚       â””â”€â”€ system.prompt      # Agent instructions
â”‚   â”œâ”€â”€ repositories/              # InMemoryConversationRepository
â”‚   â””â”€â”€ tools/
â”‚       â”œâ”€â”€ implementation/        # Tavily, LocalVectorKnowledgeBase
â”‚       â””â”€â”€ utils/                 # semanticChunker
â”‚
â””â”€â”€ app/                           # ğŸ–¥ï¸ PRESENTATION LAYER (Next.js)
    â”œâ”€â”€ page.tsx                   # Chat UI
    â””â”€â”€ api/chat/route.ts          # API endpoint
```

### Dependency Flow

```
UI (React) â†’ API Route â†’ Use Case â†’ Domain â† Ports
                                        â†‘
                              Infrastructure (Adapters)
```

> **Key Principle**: Inner layers know nothing about outer layers. Domain is pure TypeScript with zero framework dependencies.

---

## âœ¨ Features

### ğŸ” Web Search (Tavily)
Real-time information from the internet for current events, prices, and external documentation.

### ğŸ“š RAG with OpenAI Embeddings
- **Model**: `text-embedding-3-small` (1536 dimensions)
- **Semantic Chunking**: Intelligent sentence-aware splitting with overlap
- **Cosine Similarity**: Vector search with 0.3 threshold
- **Document**: Processes `rag_survey.md` (22K+ chars, 82 semantic chunks)

### ğŸ¤– Multi-Model Support
| Model ID | Provider | Use Case |
|----------|----------|----------|
| `googleai/gemini-2.5-flash` | Google | Default, fast responses |
| `openai/gpt-4o` | OpenAI | Alternative model |

### ğŸ› ï¸ Intelligent Tool Selection
The agent uses function calling to decide which tool to use:
- Questions about RAG â†’ `knowledge_base` tool
- Current events/prices â†’ `web_search` tool
- General queries â†’ Direct LLM response

---

## ğŸš€ Quick Start

### Prerequisites
- Node.js 18+
- pnpm (recommended)

### 1. Clone & Install
```bash
git clone https://github.com/MarcoLopezf/Gemini-clone.git
cd gemini-web
pnpm install
```

### 2. Configure Environment
```bash
cp .env.example .env
```

Edit `.env` with your API keys:
```env
GOOGLE_GENAI_API_KEY=your_google_key
TAVILY_API_KEY=your_tavily_key
OPENAI_API_KEY=your_openai_key
```

### 3. Run Development Server
```bash
pnpm dev
```

Open [http://localhost:3000](http://localhost:3000)

---

## ğŸ§ª Development Methodology

### Strict TDD (Test-Driven Development)

Every feature follows the **Red-Green-Refactor** cycle:

```
ğŸ”´ RED    â†’ Write failing tests first
ğŸŸ¢ GREEN  â†’ Write minimal code to pass
ğŸ”µ REFACTOR â†’ Improve while keeping tests green
```

### Verification Command
```bash
pnpm verify  # Runs: lint â†’ typecheck â†’ test â†’ build
```

### Test Coverage
```
58 tests across 8 test files
- Domain entities & value objects
- Use cases
- Infrastructure adapters
- RAG semantic chunking
```

---

## ğŸ“ Key Files

| File | Purpose |
|------|---------|
| `GenkitAgent.ts` | LLM orchestrator (~110 lines after refactor) |
| `LocalVectorKnowledgeBase.ts` | RAG implementation with OpenAI embeddings |
| `semanticChunker.ts` | Intelligent document chunking |
| `TavilySearchProvider.ts` | Web search adapter |
| `SendMessage.ts` | Core use case |
| `system.prompt` | Agent behavior instructions |

---

## ğŸ§  RAG Pipeline

```mermaid
graph LR
    A[ğŸ“„ Document] --> B[Semantic Chunker]
    B --> C[82 Chunks]
    C --> D[OpenAI Embeddings]
    D --> E[Vector Store]
    
    F[ğŸ” Query] --> G[Embed Query]
    G --> H[Cosine Similarity]
    E --> H
    H --> I[Top 3 Results]
    I --> J[ğŸ¤– LLM Context]
```

### Chunking Strategy
| Feature | Value |
|---------|-------|
| Chunk Size | ~500 chars |
| Overlap | 100 chars |
| Strategy | Sentence-aware (no mid-sentence cuts) |

---

## ğŸ”§ Technical Challenges & Solutions

### 1. Async Indexing Race Condition
**Problem**: First requests could fail if RAG indexing wasn't complete.

**Solution**: Promise-based initialization guard. `search()` awaits the indexing promise.

### 2. Genkit Embed Return Type
**Problem**: `ai.embed()` return type varies across versions.

**Solution**: `extractEmbedding()` helper that handles multiple formats.

### 3. GenkitAgent Size (252 lines)
**Problem**: Single file with multiple responsibilities.

**Solution**: Extracted into modular components:
- `GenkitClient.ts` - AI initialization
- `ToolRegistry.ts` - Tool management
- `MessageConverter.ts` - Message formatting
- `PromptLoader.ts` - Prompt loading

---

## ğŸ“Š Project Stats

| Metric | Value |
|--------|-------|
| Lines of Code | ~2,500 |
| Test Files | 8 |
| Tests | 58 |
| API Integrations | 3 (Google AI, OpenAI, Tavily) |

---

## ğŸ›£ï¸ Roadmap

- [ ] Rate limiting with Upstash
- [ ] Authentication (NextAuth)
- [ ] Persistent storage (Drizzle + SQLite)
- [ ] Streaming responses
- [ ] Multi-document RAG
- [ ] File upload support

---

## ğŸ“„ License

MIT Â© Marco Lopez

---

<div align="center">

**Built with â¤ï¸ using Clean Architecture principles**

[Report Bug](https://github.com/MarcoLopezf/Gemini-clone/issues) Â· [Request Feature](https://github.com/MarcoLopezf/Gemini-clone/issues)

</div>
